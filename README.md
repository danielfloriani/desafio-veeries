# Desafio T√©cnico Veeries: Pipeline de Dados de Lineup Portu√°rio

## üìù Descri√ß√£o do Projeto
Este projeto implementa um pipeline de dados ETL em Python para coletar, processar e agregar diariamente os dados de lineup de navios dos portos de Santos e Paranagu√°. A solu√ß√£o √© robusta, resiliente a inconsist√™ncias nos dados de origem e utiliza a arquitetura Medallion para garantir a qualidade e rastreabilidade dos dados. O resultado final √© uma base de dados anal√≠tica (Camada Ouro) com os volumes di√°rios movimentados por porto, produto e sentido.

## üèõÔ∏è Arquitetura
A solu√ß√£o foi desenvolvida utilizando a arquitetura Medallion, que separa os dados em tr√™s camadas l√≥gicas:
* **ü•â Camada Bronze:** Cont√©m os dados brutos e imut√°veis, extra√≠dos diretamente das fontes (arquivos HTML com data de extra√ß√£o). Funciona como uma fonte da verdade, permitindo o reprocessamento completo do pipeline.
* **ü•à Camada Silver:** Armazena os dados ap√≥s a consolida√ß√£o das fontes, limpeza, padroniza√ß√£o de esquema e, crucialmente, a **deduplica√ß√£o** para garantir que cada evento de embarque seja representado apenas por sua previs√£o mais recente.
* **ü•á Camada Gold:** Apresenta os dados prontos para o consumo, agregados por dimens√µes de neg√≥cio para responder √† pergunta central do desafio: os volumes di√°rios de opera√ß√£o.

## üöÄ Como Executar
1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/danielfloriani/desafio-veeries.git](https://github.com/danielfloriani/desafio-veeries.git)
    cd desafio-veeries
    ```
2.  **Crie e ative um ambiente virtual:**
    ```bash
    python -m venv venv
    # No Windows:
    venv\Scripts\activate
    # No Linux/macOS:
    source venv/bin/activate
    ```
3.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```
4.  **Execute o pipeline completo:**
    ```bash
    python pipeline.py
    ```
    Ao final da execu√ß√£o, a tabela final estar√° em `data/gold/volumes_diarios.parquet`.

## ü§î Decis√µes de Projeto e Desafios Superados
O desenvolvimento seguiu uma abordagem iterativa, focada em robustez e na qualidade do dado final. As principais decis√µes foram:
* **Processamento da "Verdade Atual":** O pipeline foi projetado para processar apenas a extra√ß√£o mais recente de cada porto, garantindo que a base de dados reflita o estado mais atualizado do lineup, evitando a complexidade de lidar com previs√µes hist√≥ricas conflitantes.
* **Deduplica√ß√£o Inteligente:** Atrav√©s da auditoria dos dados, percebeu-se que mesmo o arquivo mais recente poderia conter duplicatas. Foi implementada uma l√≥gica de deduplica√ß√£o baseada em uma chave de neg√≥cio robusta (`imo`, `viagem`, `data_prevista`, `produto`) e na data de extra√ß√£o, garantindo que cada evento de embarque seja contado apenas uma vez.
* **Robustez na Limpeza:** As fun√ß√µes de transforma√ß√£o foram constru√≠das para serem resilientes a dados "sujos". O uso de `errors='coerce'` em convers√µes num√©ricas e de data, por exemplo, previne que o pipeline quebre e garante que apenas dados v√°lidos prossigam para a camada final.
* **Valida√ß√£o Cont√≠nua:** O ceticismo sobre os resultados levou √† cria√ß√£o de scripts de auditoria, que foram cruciais para descobrir e validar o comportamento do pipeline frente a problemas do mundo real, como formatos de data inconsistentes e reagendamentos de navios.
* **Modularidade e Configura√ß√£o:** O c√≥digo foi separado por responsabilidades (`extract`, `transform`, `config`), e configura√ß√µes como mapeamentos de colunas foram externalizadas para o diret√≥rio `config`, facilitando a manuten√ß√£o futura.

## üîÆ Pr√≥ximos Passos e Melhorias
* **Orquestra√ß√£o:** Integrar o pipeline com um orquestrador como Airflow ou Prefect para agendamento e monitoramento autom√°ticos.
* **Testes Unit√°rios:** Implementar testes formais com `pytest` para as fun√ß√µes de transforma√ß√£o, garantindo que futuras altera√ß√µes n√£o quebrem a l√≥gica de neg√≥cio.
* **Containeriza√ß√£o:** Empacotar a aplica√ß√£o com Docker para garantir a portabilidade e facilitar o deploy.
* **Logging:** Substituir os comandos `print` por um sistema de `logging` mais estruturado para melhor monitoramento em produ√ß√£o.